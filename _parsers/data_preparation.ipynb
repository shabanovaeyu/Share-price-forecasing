{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Импорт модулей и функций \r\n",
    "\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import datetime as dt\r\n",
    "\r\n",
    "import nltk\r\n",
    "# nltk.download('stopwords')\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from pymorphy2 import MorphAnalyzer\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "from data_preparation import find_coefs\r\n",
    "from data_preparation import tokenizer"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": [
     0
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Чтение файлов news.csv и quotes.csv\r\n",
    "news = pd.read_csv('../_data/_raw/news.csv', sep=';')\r\n",
    "quotes = pd.read_csv('../_data/_raw/quotes.csv', sep=';')"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Создание dataset из news и quotes\r\n",
    "\r\n",
    "# В dataset попадают тикеры из news, по которым удалось собрать котировки\r\n",
    "df_tickers = pd.DataFrame({'ticker': quotes['ticker'].unique()})\r\n",
    "dataset = pd.merge(news, df_tickers, on='ticker', how='inner')\r\n",
    "\r\n",
    "# И только те примеры из news, у которых title!=NaN И content!=NaN\r\n",
    "dataset = dataset[(dataset['title'].notnull()) & (dataset['content'].notnull())]\r\n",
    "\r\n",
    "dataset = dataset[['ticker', 'year', 'month', 'day', 'title', 'content']].reset_index()"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": [
     0
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Вычисление значений к-тов a1, a2 для примеров в dataset\r\n",
    "\r\n",
    "df_result = pd.DataFrame(columns = dataset.columns)\r\n",
    "\r\n",
    "df = dataset.reset_index()\r\n",
    "\r\n",
    "for T in [30]:\r\n",
    "\r\n",
    "    for i in range(0, len(df)):\r\n",
    "       \r\n",
    "        row = df.iloc[i]\r\n",
    "        dd = row['day']\r\n",
    "        mm = row['month']\r\n",
    "        yyyy = row['year']\r\n",
    "        tick = row['ticker']\r\n",
    "        \r\n",
    "        params = {'T': T,\r\n",
    "                  'day': dd,\r\n",
    "                  'month': mm,\r\n",
    "                  'year': yyyy,\r\n",
    "                  'ticker': tick,\r\n",
    "                  'quotes': quotes,\r\n",
    "                  'dataset': dataset}\r\n",
    "\r\n",
    "        T, a1, a2 = find_coefs(params)\r\n",
    "\r\n",
    "        df.loc[i, ['T', 'a1', 'a2']] = [T, a1, a2]\r\n",
    "        \r\n",
    "    df_result = pd.concat([df_result, df], axis = 0)"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Токенизация полей title и content\r\n",
    "\r\n",
    "dataset = tokenizer(dataset, 'title')\r\n",
    "dataset = tokenizer(dataset, 'content')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Обновление dataset\r\n",
    "\r\n",
    "#1 Получение news_1 - статьи, которых нет в датасете\r\n",
    "news_1 = news.merge(dataset, how='outer', on=['year', 'month', 'day'])\r\n",
    "news_1 = news_1[news_1['ticker_y'].isnull()][['year','month','day','ticker_x','company','title_x','content_x','url_new']]\r\n",
    "news_1.rename(columns={'ticker_x': 'ticker', 'title_x': 'title', 'content_x': 'content'}, inplace=True)\r\n",
    "\r\n",
    "#2 Получение dataset_1 из news_1 и quote\r\n",
    "tickers = pd.DataFrame({ticker: quotes['ticker'].unique()})\r\n",
    "dataset_1 = pd.merge(news_1, tickers, on='ticker', how='inner')\r\n",
    "dataset_1 = dataset_1[(dataset_1['title'].notnull()) & (dataset_1['content'].notnull())]\r\n",
    "\r\n",
    "#3 Проставление к-тов a1, a2\r\n",
    "T = 30\r\n",
    "for i, idx in enumerate(list(dataset_1.index)[:]):\r\n",
    "    \r\n",
    "    row = dataset_1.loc[i]\r\n",
    "    params = {'T': T,\r\n",
    "              'day': row['day'],\r\n",
    "              'month': row['month'],\r\n",
    "              'year': row['year'],\r\n",
    "              'ticker': row['ticker'],\r\n",
    "              'quotes': quotes,\r\n",
    "              'dataset': dataset_1}\r\n",
    "    \r\n",
    "    T, a1, a2 = find_coefs(params)\r\n",
    "    dataset_1.loc[idx, ['T', 'a1', 'a2']] = [T, a1, a2]\r\n",
    "    print('i =', i, 'idx =', idx, 'period =', T, 'a2 =', a2)\r\n",
    "\r\n",
    "# 4 Токенизация полей title и conten\r\n",
    "dataset_1 = tokenizer(dataset_1, 'title')\r\n",
    "dataset_1 = tokenizer(dataset_1, 'content')\r\n",
    "\r\n",
    "# 5 Объединение фреймов данных dataset и dataset_1\r\n",
    "dataset = dataset.append(dataset_1)"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": [
     0
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Допроставление к-ов a2 ввиду появления свежих котировок\r\n",
    "\r\n",
    "print('До заполнения пропусков:', \r\n",
    "      len(dataset[dataset['a2'].isnull()]), \r\n",
    "      'строк с пустым значением a2', '\\n')\r\n",
    "\r\n",
    "T = 30\r\n",
    "\r\n",
    "for i, idx in enumerate(list(dataset.index[:])):\r\n",
    "    row = dataset.loc[i]\r\n",
    "    \r\n",
    "    if np.isnan(row['a2']):\r\n",
    "        \r\n",
    "        params = {'T': T,\r\n",
    "                  'day': row['day'],\r\n",
    "                  'month': row['month'],\r\n",
    "                  'year': row['year'],\r\n",
    "                  'ticker': row['ticker'],\r\n",
    "                  'quotes': quotes,\r\n",
    "                  'dataset': dataset}\r\n",
    "        \r\n",
    "        T, a1, a2 = find_coefs(params)\r\n",
    "        \r\n",
    "        print('К-т не был рассчитан на дату:', \r\n",
    "               row['day'], row['month'], row['year'], \r\n",
    "               '\\t', a2)\r\n",
    "        \r\n",
    "        dataset.loc[idx, ['a1', 'a2']] = a1, a2\r\n",
    "\r\n",
    "print('После заполнения пропусков:', \r\n",
    "      len(dataset[dataset['a2'].isnull()]), \r\n",
    "      'строк с пустым значением a2', '\\n')"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": [
     0
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Запись dataset в файл ../_data/dataset.v.3.2.csv\r\n",
    "df_result.to_csv('../_data/dataset.v.3.2.csv', sep=';', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ff1e1fc79923b7048a1b0a049e1f8c29b7247f7ffa1cbd35692250f92a41541"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}